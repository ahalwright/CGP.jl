Fitting regression line to scatter plot data.

https://akaysh.github.io/Linear-Regression-with-Julia/
https://stattrek.com/regression/slope-test.aspx
https://juliastats.org/GLM.jl/stable/manual/

Example:
using GLM
erdf = read_dataframe("10_27/geno_complexity10_27FMNccons.csv")
scatter(erdf.robustness,erdf.evo_count)    # Check that plot agrees with version in Paper_preview.
lreg = lm(@formula( evo_count ~ robustness), erdf )
StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Array{Float64,1}},GLM.DensePredChol{Float64,LinearAlgebra.Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}

evo_count ~ 1 + robustness

Coefficients:
──────────────────────────────────────────────────────────────────────────
                 Coef.  Std. Error       t  Pr(>|t|)  Lower 95%  Upper 95%
──────────────────────────────────────────────────────────────────────────
(Intercept)    8067.37     71.1653  113.36    <1e-99    7927.61    8207.14
robustness   -14532.6     211.42    -68.74    <1e-99  -14947.8   -14117.4
──────────────────────────────────────────────────────────────────────────
# Note that t = Coef/StdError
linfit = predict(lreg)
X = erdf.robustness;
plot(X,linfit)
scatter!(X,erdf.evo_count)

Example:
df=read_dataframe("1_23/random_neutral_walk1_13B.csv")
lreg = lm(@formula( evolvable_count ~ complexity), df )
StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Array{Float64,1}},GLM.DensePredChol{Float64,LinearAlgebra.Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}

evolvable_count ~ 1 + complexity

Coefficients:
───────────────────────────────────────────────────────────────────────
               Coef.  Std. Error      t  Pr(>|t|)  Lower 95%  Upper 95%
───────────────────────────────────────────────────────────────────────
(Intercept)  45.0493     6.93997   6.49    <1e-9     31.3604    58.7381
complexity   19.1332     1.47857  12.94    <1e-27    16.2167    22.0496
───────────────────────────────────────────────────────────────────────
tval = coef(lreg)[2]/stderror(lreg)[2]  # 12.94
log10(ccdf(d,6.))   # -9.447699190867247
quantile(d,0.025)    # -1.9723964913155794   # 0.025 for 2-sided test for 95% confidence interval
(16.2167-19.1332)/stderror(lreg)[2]   # -1.9725160751258126
# Thus, to construct the 95% confidence interval we just need to reverse thi computation
stderr = stderror(lreg)[2]  # 1.478568431851171
ccoef = coef(lreg)[2]   # 19.133169717798545
qminus = quantile(d,0.025)  # -1.9723964913155794
qplus = quantile(d,0.975)   #  1.9723964913155794
qplus*stderr + ccoef   # 22.049492904951773
qminus*stderr + ccoef  # 16.216846530645316


linreg(x, y) = hcat(fill!(similar(x), 1), x) \ y   # a \ b solves the matrix equation A*x = b
Example:  http://www.intellspot.com/linear-regression-examples/
julia> transpose(y)
1×7 LinearAlgebra.Transpose{Float64,Array{Float64,1}}:
 368.0  340.0  665.0  954.0  331.0  556.0  376.0
julia> transpose(x)
1×7 LinearAlgebraTranspose{Float64,Array{Float64,1}}:
 1.7  1.5  2.8  5.0  1.3  2.2  1.3
julia> linreg(x,y)
2-element Array{Float64,1}:
 125.83486984815626
 171.46556399132317
# regression equation y = m*x + b = 171.5*x + 125.8
