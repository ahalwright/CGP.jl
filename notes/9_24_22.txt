Exact computation of phenotype adjacency matrix

Table "Exact phenotype evolvability"
Based on data/9_24_22/exact_phnet_matrix9_24_22G.csv

p = Parameters(2,1,3,2); funcs=default_funcs(p)[1:4]
count_circuits_ch(p,funcs)  # 4096.0
gdf = read_dataframe("../data/9_24_22/exact_phnet_matrix9_24_22G.csv")
E = df_to_matrix(gdf,2)
sum(E) 61440.0
rc = random_chromosome(p,funcs);
mutate_all(rc,funcs,output_outputs=true) 15-element Vector{Vector{UInt16}}:   # number of mutations is 15
15*4096 = 61440  
ov = map( x->output_values(int_to_chromosome(x,p,funcs))[1], 0:4095 );  # list of all output values
findall( x->x==0x0002, ov ) 96-element Vector{Int64}:  # Conclude that redundancy of 0x0002 is 96
div(sum(E[:,3]),15)  #  96.0  
# conclude that redundancy of a phenotype is the sum of the corresding row of E divided by number of mutations (15)

Phenotype robustness should be the diagonal element divided by the sum of the corresponding row:
Example: phenotype 0x2 corresponds to i=3 
E[i,i]/sum(E[:,i]) 0.2111111111111111

B = map( x->(iszero(x) ? 0 : 1), E );   # Binary matrix
The phenotype evolvability should be the sum of the non-diagonal entries of the corresponding row:
Example: phenotype 0x2 corresponds to i=3 
sum( ( i!=j ? B[i,j] : 0) for j = 1:size(B)[1] )
# Evolvabilities computed by random_walks_parallel are correct

@time df = include("../data/9_24_22/run_phnet_matrixD.jl")
E = df_to_matrix(df,2)
bv = BitVector(map(i->(sum(E[i,:]) > 0 ? 1 : 0), 1:16))
===========================================

Parallelizing pheno_network_matrix_df() in Fnc.jl.
There are two parts:  
*  pheno_counts_ch()   # This ran out of memory on fluda with 5 gates.
*  matrix computation

Note:  notes/11_8_22.txt  Plot of exact lg robustness vs exact evolvability

Attempts to pmap parallelize pheno_counts_ch() took lots of time and failed.
One bug was including a helper function in the main function which also used the variable result.
Changes to result in the helper function changed result in the main function.
However, the more time consuming part is constructing the matrix.

I came up with a multi-threading solution to parallelize the matrix computation. 
I created phnet_matrix_atomic as a matrix of Atomic{Int64}(0).  Testing showed that:
* Incrementing this matrix is just as fast as incrementing a matrix of Int64s.
* This technique eliminates race conditions.
* puts a separate lock on each matrix entry

# Added Q df and matrix on 1/13/23

phdfG = read_dataframe("../data/9_24_22/exact_phnet_matrix9_24_22G.csv")   # Not Normalized  Integer 4 funcs 2 inputs 3 gates 2 levelsback no XOR
5gts 3lb 5funcs 48543 seconds = 13.5 hours on surt2
Results for M and P:  3 inputs, 5 gates  (N and P are the same except for comments).
phdfM = read_dataframe("../data/9_24_22/phnet_matrix9_24_22M.csv")   # Normalized---Float  5 funcs
phdfP = read_dataframe("../data/9_24_22/phnet_matrix9_24_22P.csv")   # Not Normalized  Integer 4 funcs
phdfQ = read_dataframe("../data/9_24_22/phnet_matrix9_24_22Q.csv")   # Not Normalized  Integer 5 funcs
# verify dataframes:
sum(phdfP.redund), sum(phdfQ.redund) #  (60466177, 184528126)
phnM = df_to_matrix( phdfM, 3, denormalize=false );  # df_to_matrix_mt() is faster
phnP = df_to_matrix( phdfP, 3, denormalize=false );  # df_to_matrix_mt() is faster
phnQ = df_to_matrix( phdfQ, 3, denormalize=false );  # df_to_matrix_mt() is faster
evdM = entropy_evolvability( phnM, include_self_edges=true);
evdP = entropy_evolvability( phnP, include_self_edges=true);
evdQ = entropy_evolvability( phnQ, include_self_edges=true);
ppdfM = DataFrame( :goal=>collect(0x0000:0x00ff), :ent_evol=>evdM, :Kcomp=>map(ph->kdict[ph],collect(0x0000:0x00ff)),:lgredund=>map(ph->lg10( rdict[ph] ), collect(0x0000:0x00ff)))
ppdfP = DataFrame( :goal=>collect(0x0000:0x00ff), :ent_evol=>evdP, :Kcomp=>map(ph->kdict[ph],collect(0x0000:0x00ff)),:lgredund=>map(ph->lg10( rdict[ph] ), collect(0x0000:0x00ff)))
scatter(ppdfM.ent_evol,ppdfM.lgredund,labels="log redund vs entropy evolvability",xlabel="entropy evolvability",ylabel="log redundancy",title="exact lgredund vs entropy evolv 3x1 5gts3lb 5funcs",legend=:topright)
savefig("../data/9_24_22/exact_lgredund_vs_entropy_evolv_3x1_5gts3lb_5funcs.png")
sum(phdfM.redund)  # 184_528_126
phdf[phdfM.redund.<=1600,[:goal,:redund]]
4×2 DataFrame
 Row │ goal   redund
   │ String7  Int64
─────┼─────────────────
   1 │ 0x29    832
   2 │ 0x49     1024
   3 │ 0xb6     1024
   4 │ 0xd6    832
ss1M = map(ph->length(shape_space_evolvability( ph, phnM, 1 )),collect(0x0000:0x00ff));
(mean(ss1M),findmin(ss1M),findmax(ss1M)) #  (173.0546875, (111, 59), (255, 1))
ss2M = map(ph->length(shape_space_evolvability( ph, phnM, 2 )),collect(0x0000:0x00ff));
(mean(ss2M),findmin(ss2M),findmax(ss2M)) #  (256.0, (256, 1), (256, 1))

Results for N:  Note:  phnet_matrix9_24_22N.csv and phnet_matrix9_24_22P.csv are the same matrix.  Files only differ in comments.
data/9_24_22/phnet_matrix9_24_22N.csv
phdfN = read_dataframe("../data/9_24_22/phnet_matrix9_24_22N.csv")
#  5gts 3lb 4funcs 14084 seconds = 3.9 hours on surt2
phnN = df_to_matrix( phdfN, 3, denormalize=false );
evdN = entropy_evolvability( phnN, include_self_edges=true);
ppdfN = DataFrame( :goal=>collect(0x0000:0x00ff), :ent_evol=>evdN, :Kcomp=>map(ph->kdict[ph],collect(0x0000:0x00ff)),:lgredund=>map(ph->lg10( rdict[ph] ), collect(0x0000:0x00ff)))
scatter(ppdfN.ent_evol,ppdfN.lgredund,labels="log redund vs entropy evolvability",xlabel="entropy evolvability",ylabel="log redundancy",title="exact lgredund vs entropy evolv 3x1 5gts3lb 4funcs",legend=:bottomright)
savefig("../data/9_24_22/exact_lgredund_vs_entropy_evolv_3x1_5gts3lb_4funcs.png")
ss1N = map(ph->length(shape_space_evolvability( ph, phnN, 1 )),collect(0x0000:0x00ff));
(mean(ss1N),findmin(ss1N),findmax(ss1N)) #  (46.203125, (0, 7), (166, 1))
ss2N = map(ph->length(shape_space_evolvability( ph, phnN, 2 )),collect(0x0000:0x00ff));
(mean(ss2N),findmin(ss2N),findmax(ss2N)) #  (107.640625, (0, 7), (166, 1))
findall(x->x==0,phdfN.redund) # 90-element Vector{Int64}:
sum(phdfN.redund)  # 60_466_177

Can get exact degree, strength, and evolution evolvabilities.

A small example:
data/9_24_22/run_phnet_matrixG.jl: 
data/9_24_22/exact_phnet_matrix9_24_22G.csv
data/9_24_22/exact_phnet_matrix9_24_22G.tex

=================================================
Computing K complexities for all 4x1 phenos

8_9_22/run_k_complexity4x1S.jl  ran but turned out to have length(funcs)==5
8_9_22/run_k_complexity4x1T.jl  started crashed.
8_9_22/run_k_complexity4x1M.jl  

9/26/22:  Commented out computation of complexity
=================================================
Cooper assignnment:

You should send me code and a brief report on your previous assignment.

Your assignment is to explore the effectiveness of epochal (neutral) evolution for 4, 5, 6 input phenotypes.

Starting with 4 inputs, what parameter settings are more effective for evolving random phenotypes, and how do
the parameter setting affect the effectiveness (success rate)?  The parameters in question are: (see src/Parameters.jl)

1.  Number of gates.  p.numinteriors
2.  Levelsback.  p.numlevelsback
3.  Logic gates used:  either AND,OR,NAND,NOR, or these 4 plus XOR.  See Func.jl for the setting of default_funcs()
4.  maxsteps.  (A parameter of neutral_evolution().)
5.  maxtries.  (A parameter of neutral_evolution().)

There is Cartesian Genetic Programming (CGP) research that shows that a large number of inactive gates is good
for evolvability.  A gate is active in a circuit if it contributes to the output of the circuit.  The Kolmogorov
complexity of a phenotype is the minimum number of gates needed for a circuit to map to the phenotype.  Such
a circuit must have no active gates because an equivalent circuit to a circuit with inactive gates can be constructed
by eliminating the inactive gates.  Increasing the number of inactive gates increases robustness which helps to
enable neutral or epochal evolution.

It is not completely clear how to measure the success of neutral evolution when it sometimes fails.  Average steps
is very inconsistent since when there is a failure on a run of neutral_evolution(), average steps gets a big boost.

Some quantities that would be good to relate to the effectiveness of epochal evolution are:
1.  Number inactive gates.  Look at function number_active_gates() in Chromosome.jl.
2.  Tononi complexity.  However, as the number of gates and levelsback increases, this gets increasingly expensive
to compute.  My standard function for computing Tononi complexity is complexity5().
3.  Kolmogorov complexity:  Only possible for 3 and 4 inputs.  

You will need to parallelize your code by using pmap() (or maybe Folds.pmap(), but this didn't work as well for me).
There are many examples of the used of pmap() in my code.  A typical paradigm is that I will write a function
which I will just call fnc() for now, and then a will write another function run_fnc() which calls fnc() using pmap().
The run_fnc() function will collect and process the results and then write the results to a CSV file.  

A specific example is the functions run_pheno_evolve() and one of the versions of pheno_evolve() which are in Evolve.jl.

You can test parallelization on xps which has 4 cores and maybe on your Windows machine.  For "production" runs you will
need to use either surt2.cs.umt.edu (28 cores) or fluda.cs.umt.edu (12 cores or 24 pseudo cores).  We will need to have
an in-person or zoom session on moving files between Linux machines.


