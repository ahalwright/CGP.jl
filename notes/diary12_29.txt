Testing the hypothesis that complexities of phenotypes (goals) by evolution is greater 
than complexities by sampling.
using Statistics
using HypothesisTests

round2(x) = round(100*x)/100  # Reduces size of CSV file
cmplx = map(round2,db.complexities)

For 4x1 8 gates, 5 levelsback:
Ran data/12_29/run_geno_complexityA.jl on lycosa with 100 goals, 100 maxreps which took over 10 hours
   to obtain goal complexities.  Transferrred geno_complexity12_29A.csv to surt2.
  gdf = read_dataframe("../data/12_29/geno_complexity12_29A.csv") 
Ran data/12_29/run_circuit_complexitiesM.jl on surt2 to obtain 200,000,000 = 2*10^8  random circuit 
    complexities.  
  cdf = read_dataframe("../data/12_29/circuit_complexities12_29M.csv")
df.goal = gdf.goal
df.goal_complexity=gdf.complexity
df.circ_complexity = [mean(cdf[cdf.goals.==g,:complexities]) for g in gdf.goal ]
df.circ_length = [length(cdf[cdf.goals.==g,:complexities]) for g in gdf.goal ]
diff = filter(x->x>=-1000.0,[df.goal_complexity[i]-df.circ_complexity[i] for i = 1:size(df)[1] ] )
mean(diff)   # 0.24257980206526056
# How do I test for significance???
# Note that data/12_18/circuit_complexities12_18C.csv is another circ data set for 8gts5lb.
ddf = read_dataframe("../data/12_18/circuit_complexities12_18C.csv")
edf = DataFrame()
edf.goals = vcat(cdf.goals,ddf.goals) 
edf.complexities = vcat(cdf.complexities,ddf.complexities) 
df = DataFrame()
df.goal = gdf.goal 
df.goal_complexity=gdf.complexity 
df.circ_complexity = [mean(edf[edf.goals.==g,:complexities]) for g in gdf.goal ]
diff = filter(x->x>=-1000.0,[df.goal_complexity[i]-df.circ_complexity[i] for i = 1:size(df)[1] ] )
length(diff)   # 84
mean(diff)     # 0.2229785664783637
mean(gdf.complexity)  # 4.389416841841202
pvalue(OneSampleTTest(diff)) #  7.437681191950176e-10

For 4x1 11 gates, 8 levelsback:
Cmeopied data/10_27/geno_complexity10_27FMNccons.csv to surt2.
data/12_20/circuit_complexities12_20DR.csv is a circ data set for 11gts8lb, but 1/10 the size of above.
@time ddf = include("../data/12_29/run_circuit_complexitiesD.jl")   # 59404 seconds
cmplx = map(round2,ddf.complexities)
ddf.complexities = cmplx
write_dataframe_with_comments(ddf,"../data/12_29/circuit_complexities12_29D.csv","../data/12_29/circuit_complexities12_29DR.csv")
Started another julia instance:
cdf = read_dataframe("../data/12_29/circuit_complexities12_29DR.csv")
gdf = read_dataframe("../data/10_27/geno_complexity10_27FMNccons.csv")  
df = DataFrame()
df.goal = gdf.goal
df.goal_complexity=gdf.complexity
df.circ_complexity = [mean(cdf[cdf.goals.==g,:complexities]) for g in gdf.goal ]
diff = filter(x->x>=-1000.0,[df.goal_complexity[i]-df.circ_complexity[i] for i = 1:size(df)[1] ] )
length(diff) #  570
mean(diff)   #  0.5373611764271821
mean(df.goal_complexity)     # 6.495215849566641
pvalue(OneSampleTTest(diff)) #  1.0353222259465128e-89


For 3x1 7 gates, 4 levelsback:
on surt2
#@time pdf = include("../data/12_29/run_circuit_complexitiesP.jl")
pdf = read_dataframe("../data/12_29/circuit_complexities12_29PN.csv")
gdf = read_dataframe("../data/12_29/geno_properties12_29B.csv")
df = DataFrame()
df.goal = gdf.goal
df.goal_complexity=gdf.complexity 
df.circ_complexity = [mean(pdf[pdf.goals.==g,:complexities]) for g in gdf.goal ]  # I don't see any NaN's 
diff = filter(x->x>=-1000.0,[df.goal_complexity[i]-df.circ_complexity[i] for i = 1:size(df)[1] ] )
length(diff)     # 256 
mean(diff)       # 0.17534405787362237
std(diff)        # 0.1473079164811341
length(filter(x->x>=0,diff))    # 236
using HypothesisTests
pvalue(OneSampleTTest(diff)) # 6.618060462800393e-51  Two-sided test against 0.0
